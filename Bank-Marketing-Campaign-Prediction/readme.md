# ğŸ¦ Bank Marketing Campaign Success Prediction  
### AI-Powered Customer Conversion Intelligence
 
> Turning Blind Marketing into Data-Driven Targeting 

---

## ğŸ“Œ Overview

Banks spend huge resources running marketing campaigns to promote term deposits.  
But not every customer converts.

This project builds a **Machine Learning Classification System** that predicts:

> ğŸ’¬ *Will a customer subscribe to a term deposit?*

By using structured banking data and a Random Forest classifier, we convert a traditional marketing problem into a **data-driven decision system**.

---

## ğŸ¯ Business Problem

Traditional Campaign Approach:

- ğŸ“ Call thousands of customers
- ğŸ’° Spend large operational cost
- ğŸ“‰ Low conversion rate

Smart AI Approach:

- ğŸ¯ Predict high-probability customers
- ğŸ“Š Target only promising leads
- ğŸ’µ Improve ROI

This project answers:

> â€œCan we predict subscription likelihood before contacting the customer?â€

---

## ğŸ“‚ Dataset Information

**Dataset:** Bank Marketing Dataset  
**Source:** Kaggle  
**Link:** https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset  

### ğŸ” Features Used

- `age`
- `balance`
- `campaign`
- `housing`
- `poutcome`

### ğŸ¯ Target Variable

- `deposit`
  - `yes` â†’ Subscribed
  - `no` â†’ Not Subscribed

---

## âš™ï¸ Machine Learning Pipeline

### 1ï¸âƒ£ Data Loading

```python
import pandas as pd
df = pd.read_csv("bank.csv")
```

---

### 2ï¸âƒ£ Feature Selection

```python
df = df[[
    "age",
    "balance",
    "campaign",
    "housing",
    "poutcome",
    "deposit"
]]
```

---

### 3ï¸âƒ£ Encoding Categorical Features

```python
df["housing"] = df["housing"].map({"yes": 1, "no": 0})

df["poutcome"] = df["poutcome"].map({
    "success": 2,
    "failure": 1,
    "other": 0,
    "unknown": 0
})

df["deposit"] = df["deposit"].map({"yes": 1, "no": 0})
```

---

### 4ï¸âƒ£ Train-Test Split

```python
from sklearn.model_selection import train_test_split

X = df.drop("deposit", axis=1)
y = df["deposit"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

---

### 5ï¸âƒ£ Model Selection

We used **Random Forest Classifier** because:

- Works well on structured data  
- Handles non-linear relationships  
- Reduces overfitting  
- Provides stable performance  

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=200,
    class_weight="balanced",
    random_state=42
)

model.fit(X_train, y_train)
```

---

### 6ï¸âƒ£ Model Evaluation

```python
from sklearn.metrics import accuracy_score, classification_report

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

---

## ğŸ“ˆ Model Performance

- Test Accuracy: ~85â€“86%
- Balanced precision & recall
- Handles class imbalance using `class_weight="balanced"`

---

## ğŸ–¥ï¸ GUI Application

A professional desktop GUI built using **Tkinter** allows users to:

- Enter customer details
- Analyze subscription probability
- View dynamic percentage output
- See clear decision result (Likely / Not Likely)

### Example High Probability Input

| Feature | Value |
|----------|--------|
| Age | 45 |
| Balance | 400000 |
| Campaign | 1 |
| Housing | No |
| Poutcome | Success |

### Example Low Probability Input

| Feature | Value |
|----------|--------|
| Age | 21 |
| Balance | 2000 |
| Campaign | 8 |
| Housing | Yes |
| Poutcome | Failure |

---

## ğŸ“ Project Structure

```
ğŸ“¦ Bank-Marketing-Campaign-Success-Prediction
â”‚
â”œâ”€â”€ ğŸ“„ AIML_project.ipynb      # Model training notebook
â”œâ”€â”€ ğŸ app.py                  # GUI application
â”œâ”€â”€ ğŸ“Š bank.csv                # Dataset
â”œâ”€â”€ ğŸ“˜ README.md               # Project documentation
â””â”€â”€ ğŸ“¦ requirements.txt        # Dependencies
```

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/Aman-Tech990/Bank-Marketing-Campaign-Success-Prediction
cd Bank-Marketing-Campaign-Success-Prediction
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install pandas scikit-learn
```

### 3ï¸âƒ£ Run Application

```bash
python app.py
```

---

## ğŸ§  Why Random Forest?

Random Forest:

1. Builds multiple decision trees  
2. Uses random subsets of data  
3. Combines predictions via majority voting  

This improves accuracy and reduces variance compared to a single decision tree.

---

## ğŸ”§ Future Enhancements

- Add ROC-AUC curve visualization  
- Deploy using Streamlit / Flask  
- Add feature importance graph  
- Implement hyperparameter tuning  
- Deploy as cloud-hosted web app  

---

## ğŸ‘¥ Team NeuroX

- Aman Parida  
- Rohit Kumar Pradhan  
- Mantosa Kumar Biswal  
- Pratyush Beura  
- Rohan Sahoo  
- Chandra Shekhar Sahoo  

B.Tech Computer Science (Data Science)  
Semester â€“ 4th  

---

## ğŸ’¡ Real-World Impact

This system helps banks:

- ğŸ¯ Improve targeting accuracy  
- ğŸ’° Reduce marketing costs  
- ğŸ“Š Increase campaign ROI  
- ğŸ§  Make data-driven decisions  

Machine Learning turns guessing into intelligence.

---

## â­ If You Found This Useful

Give this repository a â­ and support the project!
